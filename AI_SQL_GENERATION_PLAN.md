# üìä K·∫æ HO·∫†CH X√ÇY D·ª∞NG H·ªÜ TH·ªêNG AI TEXT-TO-SQL CHO GIA PH·∫¢

## üîç PH√ÇN T√çCH DATABASE HI·ªÜN T·∫†I

### C·∫•u tr√∫c b·∫£ng `thanhvien` (Members):
```sql
CREATE TABLE `thanhvien` (
  `thanhVienId` int NOT NULL,
  `dongHoId` varchar(50) NOT NULL,
  `hoTen` varchar(255),           -- T√™n ƒë·∫ßy ƒë·ªß
  `gioiTinh` tinyint,              -- 0: N·ªØ, 1: Nam
  `ngaySinh` date,
  `ngayMat` date,
  `noiSinh` varchar(255),
  `noiMat` varchar(255),
  `ngheNghiep` varchar(255),       -- Ngh·ªÅ nghi·ªáp
  `trinhDoHocVan` varchar(255),
  `soDienThoai` varchar(11),
  `diaChiHienTai` varchar(255),
  `tieuSu` text,
  `anhChanDung` varchar(255),
  `doiThuoc` int,                  -- ƒê·ªùi th·ª© (generation)
  
  -- QUAN H·ªÜ GIA ƒê√åNH (L∆∞u tr·ª±c ti·∫øp trong b·∫£ng)
  `chaId` int,                     -- ID c·ªßa cha
  `meId` int,                      -- ID c·ªßa m·∫π
  `voId` int,                      -- ID c·ªßa v·ª£ (n·∫øu l√† nam)
  `chongId` int,                   -- ID c·ªßa ch·ªìng (n·∫øu l√† n·ªØ)
  
  PRIMARY KEY (`dongHoId`, `thanhVienId`),
  FOREIGN KEY (`dongHoId`, `chaId`) REFERENCES `thanhvien`,
  FOREIGN KEY (`dongHoId`, `meId`) REFERENCES `thanhvien`
)
```

### B·∫£ng `quanhe` (Relationships):
```sql
CREATE TABLE `quanhe` (
  `quanHeId` varchar(50) NOT NULL,
  `thanhVien1Id` int,
  `thanhVien2Id` int,
  `loaiQuanHeId` varchar(50),
  `ngayBatDau` date,
  `ngayKetThuc` date,
  `ghiChu` text,
  PRIMARY KEY (`quanHeId`)
)
```

**‚ö†Ô∏è V·∫§N ƒê·ªÄ HI·ªÜN T·∫†I:**
- B·∫£ng `quanhe` TR·ªêNG (kh√¥ng c√≥ data)
- B·∫£ng `loaiquanhe` TR·ªêNG (kh√¥ng c√≥ ƒë·ªãnh nghƒ©a lo·∫°i quan h·ªá)
- T·∫•t c·∫£ quan h·ªá ƒëang l∆∞u trong b·∫£ng `thanhvien` qua c√°c c·ªôt: `chaId`, `meId`, `voId`, `chongId`

---

## üí° ƒê·ªÄ XU·∫§T C·∫§U TR√öC M·ªöI

### Option 1: GI·ªÆ NGUY√äN C·∫§U TR√öC HI·ªÜN T·∫†I ‚≠ê KHUY·∫æN NGH·ªä
**∆Øu ƒëi·ªÉm:**
- Kh√¥ng c·∫ßn migration data
- Query ƒë∆°n gi·∫£n, nhanh
- Ph√π h·ª£p v·ªõi c√¢y gia ph·∫£ (parent-child relationship)

**Nh∆∞·ª£c ƒëi·ªÉm:**
- Kh√≥ m·ªü r·ªông cho c√°c quan h·ªá ph·ª©c t·∫°p (anh em, c√¥ d√¨, ch√∫ b√°c...)
- B·∫£ng `quanhe` kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng

**C√°ch x·ª≠ l√Ω:**
```sql
-- T√¨m cha m·∫π c·ªßa m·ªôt ng∆∞·ªùi
SELECT 
    cha.hoTen as ten_cha,
    me.hoTen as ten_me
FROM thanhvien tv
LEFT JOIN thanhvien cha ON tv.chaId = cha.thanhVienId AND tv.dongHoId = cha.dongHoId
LEFT JOIN thanhvien me ON tv.meId = me.thanhVienId AND tv.dongHoId = me.dongHoId
WHERE tv.hoTen = 'Nguy·ªÖn VƒÉn A' AND tv.dongHoId = ?

-- T√¨m con c·ªßa m·ªôt ng∆∞·ªùi
SELECT hoTen, gioiTinh, ngheNghiep
FROM thanhvien
WHERE (chaId = ? OR meId = ?) AND dongHoId = ?

-- T√¨m v·ª£/ch·ªìng
SELECT 
    CASE 
        WHEN tv.gioiTinh = 1 THEN vo.hoTen
        ELSE chong.hoTen
    END as ten_vo_chong
FROM thanhvien tv
LEFT JOIN thanhvien vo ON tv.voId = vo.thanhVienId AND tv.dongHoId = vo.dongHoId
LEFT JOIN thanhvien chong ON tv.chongId = chong.thanhVienId AND tv.dongHoId = chong.dongHoId
WHERE tv.hoTen = 'Nguy·ªÖn VƒÉn A' AND tv.dongHoId = ?
```

### Option 2: S·ª¨ D·ª§NG B·∫¢NG `quanhe` (C·∫ßn migration)
**∆Øu ƒëi·ªÉm:**
- Linh ho·∫°t, m·ªü r·ªông d·ªÖ d√†ng
- C√≥ th·ªÉ l∆∞u nhi·ªÅu lo·∫°i quan h·ªá ph·ª©c t·∫°p
- Chu·∫©n database design

**Nh∆∞·ª£c ƒëi·ªÉm:**
- C·∫ßn migrate to√†n b·ªô data hi·ªán t·∫°i
- Query ph·ª©c t·∫°p h∆°n
- C·∫ßn populate b·∫£ng `loaiquanhe`

**C·∫•u tr√∫c ƒë·ªÅ xu·∫•t:**
```sql
-- B·∫£ng lo·∫°i quan h·ªá
INSERT INTO loaiquanhe VALUES
('LQH001', 'Cha - Con', 'Quan h·ªá cha con', 1, 'system', NOW(), NULL),
('LQH002', 'M·∫π - Con', 'Quan h·ªá m·∫π con', 1, 'system', NOW(), NULL),
('LQH003', 'V·ª£ - Ch·ªìng', 'Quan h·ªá v·ª£ ch·ªìng', 1, 'system', NOW(), NULL),
('LQH004', 'Anh - Em', 'Quan h·ªá anh em ru·ªôt', 1, 'system', NOW(), NULL);

-- Migration script ƒë·ªÉ chuy·ªÉn data t·ª´ thanhvien sang quanhe
INSERT INTO quanhe (quanHeId, thanhVien1Id, thanhVien2Id, loaiQuanHeId, dongHoId1, dongHoId2)
SELECT 
    UUID() as quanHeId,
    chaId as thanhVien1Id,
    thanhVienId as thanhVien2Id,
    'LQH001' as loaiQuanHeId,
    dongHoId as dongHoId1,
    dongHoId as dongHoId2
FROM thanhvien
WHERE chaId IS NOT NULL;
```

---

## üéØ QUY·∫æT ƒê·ªäNH: OPTION 1 - GI·ªÆ NGUY√äN C·∫§U TR√öC

**L√Ω do:**
1. Kh√¥ng c·∫ßn migration (r·ªßi ro th·∫•p)
2. ƒê·ªß ƒë√°p ·ª©ng 90% c√¢u h·ªèi th√¥ng th∆∞·ªùng
3. Performance t·ªët h∆°n
4. D·ªÖ maintain

**K·∫ø ho·∫°ch:**
- S·ª≠ d·ª•ng c·∫•u tr√∫c hi·ªán t·∫°i v·ªõi `chaId`, `meId`, `voId`, `chongId`
- B·ªï sung b·∫£ng `quanhe` sau n·∫øu c·∫ßn (cho quan h·ªá ph·ª©c t·∫°p)

---

## ü§ñ CH·ªåN MODEL TI·∫æNG VI·ªÜT T·ª™ HUGGING FACE

### Ti√™u ch√≠ l·ª±a ch·ªçn:
1. ‚úÖ Hi·ªÉu ti·∫øng Vi·ªát t·ªët
2. ‚úÖ C√≥ th·ªÉ fine-tune
3. ‚úÖ K√≠ch th∆∞·ªõc ph√π h·ª£p (< 10B parameters)
4. ‚úÖ Open source
5. ‚úÖ C√≥ community support

### Top 5 Models ƒë·ªÅ xu·∫•t:

#### 1. **Qwen/Qwen2.5-Coder-7B-Instruct** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê KHUY·∫æN NGH·ªä
- **Link**: https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct
- **Size**: 7B parameters
- **∆Øu ƒëi·ªÉm**:
  - Hi·ªÉu ti·∫øng Vi·ªát t·ªët (multilingual)
  - Chuy√™n v·ªÅ code generation (SQL l√† code)
  - C√≥ th·ªÉ ch·∫°y local v·ªõi Ollama
  - ƒê√£ c√≥ s·∫µn trong h·ªá th·ªëng c·ªßa b·∫°n
  - Community l·ªõn
- **Nh∆∞·ª£c ƒëi·ªÉm**:
  - C·∫ßn fine-tune ƒë·ªÉ t·ªët h∆°n v·ªõi SQL
- **ƒê√°nh gi√°**: 9/10

#### 2. **defog/sqlcoder-7b-2**
- **Link**: https://huggingface.co/defog/sqlcoder-7b-2
- **Size**: 7B parameters
- **∆Øu ƒëi·ªÉm**:
  - Chuy√™n v·ªÅ SQL generation
  - Accuracy cao tr√™n Spider benchmark
  - ƒê√£ ƒë∆∞·ª£c train v·ªõi nhi·ªÅu database schema
- **Nh∆∞·ª£c ƒëi·ªÉm**:
  - Kh√¥ng hi·ªÉu ti·∫øng Vi·ªát t·ªët
  - C·∫ßn fine-tune nhi·ªÅu cho ti·∫øng Vi·ªát
- **ƒê√°nh gi√°**: 7/10

#### 3. **vinai/PhoGPT-7B5-Instruct**
- **Link**: https://huggingface.co/vinai/PhoGPT-7B5-Instruct
- **Size**: 7.5B parameters
- **∆Øu ƒëi·ªÉm**:
  - Model ti·∫øng Vi·ªát thu·∫ßn t√∫y
  - Hi·ªÉu context Vi·ªát Nam t·ªët
  - ƒê∆∞·ª£c train b·ªüi VinAI
- **Nh∆∞·ª£c ƒëi·ªÉm**:
  - Kh√¥ng chuy√™n v·ªÅ SQL
  - C·∫ßn fine-tune nhi·ªÅu
  - Community nh·ªè h∆°n
- **ƒê√°nh gi√°**: 6/10

#### 4. **meta-llama/Llama-3.1-8B-Instruct**
- **Link**: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct
- **Size**: 8B parameters
- **∆Øu ƒëi·ªÉm**:
  - Model m·∫°nh, ƒëa nƒÉng
  - Hi·ªÉu nhi·ªÅu ng√¥n ng·ªØ (bao g·ªìm ti·∫øng Vi·ªát)
  - Community l·ªõn
- **Nh∆∞·ª£c ƒëi·ªÉm**:
  - C·∫ßn license t·ª´ Meta
  - Kh√¥ng chuy√™n v·ªÅ SQL
- **ƒê√°nh gi√°**: 8/10

#### 5. **microsoft/phi-3-mini-4k-instruct**
- **Link**: https://huggingface.co/microsoft/phi-3-mini-4k-instruct
- **Size**: 3.8B parameters
- **∆Øu ƒëi·ªÉm**:
  - Nh·ªè g·ªçn, ch·∫°y nhanh
  - Hi·ªÉu ti·∫øng Vi·ªát kh√° t·ªët
  - C√≥ th·ªÉ ch·∫°y tr√™n GPU y·∫øu
- **Nh∆∞·ª£c ƒëi·ªÉm**:
  - Accuracy th·∫•p h∆°n model l·ªõn
  - Kh√¥ng chuy√™n v·ªÅ SQL
- **ƒê√°nh gi√°**: 7/10

---

## üèÜ QUY·∫æT ƒê·ªäNH CU·ªêI C√ôNG

### Model ch√≠nh: **Qwen/Qwen2.5-Coder-7B-Instruct**

**L√Ω do:**
1. B·∫°n ƒë√£ c√≥ Ollama v·ªõi Qwen2.5 setup s·∫µn
2. Hi·ªÉu ti·∫øng Vi·ªát t·ªët
3. Chuy√™n v·ªÅ code/SQL generation
4. C√≥ th·ªÉ fine-tune v·ªõi LoRA
5. Community support t·ªët

### Chi·∫øn l∆∞·ª£c:
**Phase 1: Prompt Engineering (1 tu·∫ßn)**
- Test v·ªõi prompt t·ªët tr∆∞·ªõc
- Kh√¥ng c·∫ßn train
- ƒê√°nh gi√° accuracy

**Phase 2: Few-shot Learning (1 tu·∫ßn)**
- Th√™m examples v√†o prompt
- C·∫£i thi·ªán accuracy

**Phase 3: Fine-tuning v·ªõi LoRA (2-3 tu·∫ßn)**
- N·∫øu Phase 1-2 kh√¥ng ƒë·ªß t·ªët
- Train v·ªõi 500-1000 examples
- S·ª≠ d·ª•ng LoRA ƒë·ªÉ nh·∫π h∆°n

---

## üìù DATASET TRAINING C·∫¶N T·∫†O

### C·∫•u tr√∫c file JSON:
```json
{
  "schema": "...",  // Database schema
  "question": "...", // C√¢u h·ªèi ti·∫øng Vi·ªát
  "sql": "...",      // SQL query
  "explanation": "..." // Gi·∫£i th√≠ch (optional)
}
```

### C√°c lo·∫°i c√¢u h·ªèi c·∫ßn cover:

#### 1. Th√¥ng tin c√° nh√¢n (20%)
```json
{
  "question": "Ngh·ªÅ nghi·ªáp c·ªßa Nguy·ªÖn VƒÉn A l√† g√¨?",
  "sql": "SELECT ngheNghiep FROM thanhvien WHERE hoTen = 'Nguy·ªÖn VƒÉn A' AND dongHoId = ?"
}
```

#### 2. Quan h·ªá cha m·∫π (25%)
```json
{
  "question": "Nguy·ªÖn VƒÉn A l√† con c·ªßa ai?",
  "sql": "SELECT cha.hoTen as ten_cha, me.hoTen as ten_me FROM thanhvien tv LEFT JOIN thanhvien cha ON tv.chaId = cha.thanhVienId AND tv.dongHoId = cha.dongHoId LEFT JOIN thanhvien me ON tv.meId = me.thanhVienId AND tv.dongHoId = me.dongHoId WHERE tv.hoTen = 'Nguy·ªÖn VƒÉn A' AND tv.dongHoId = ?"
}
```

#### 3. T√¨m con c√°i (20%)
```json
{
  "question": "Nguy·ªÖn VƒÉn A c√≥ m·∫•y con?",
  "sql": "SELECT COUNT(*) as so_con FROM thanhvien WHERE (chaId = (SELECT thanhVienId FROM thanhvien WHERE hoTen = 'Nguy·ªÖn VƒÉn A' AND dongHoId = ?) OR meId = (SELECT thanhVienId FROM thanhvien WHERE hoTen = 'Nguy·ªÖn VƒÉn A' AND dongHoId = ?)) AND dongHoId = ?"
}
```

#### 4. V·ª£/ch·ªìng (15%)
```json
{
  "question": "V·ª£ c·ªßa Nguy·ªÖn VƒÉn A t√™n g√¨?",
  "sql": "SELECT vo.hoTen FROM thanhvien tv JOIN thanhvien vo ON tv.voId = vo.thanhVienId AND tv.dongHoId = vo.dongHoId WHERE tv.hoTen = 'Nguy·ªÖn VƒÉn A' AND tv.dongHoId = ?"
}
```

#### 5. L·ªçc theo gi·ªõi t√≠nh (10%)
```json
{
  "question": "Ai l√† con trai c·ªßa Nguy·ªÖn VƒÉn A?",
  "sql": "SELECT hoTen FROM thanhvien WHERE (chaId = (SELECT thanhVienId FROM thanhvien WHERE hoTen = 'Nguy·ªÖn VƒÉn A' AND dongHoId = ?) OR meId = (SELECT thanhVienId FROM thanhvien WHERE hoTen = 'Nguy·ªÖn VƒÉn A' AND dongHoId = ?)) AND gioiTinh = 1 AND dongHoId = ?"
}
```

#### 6. Quan h·ªá ph·ª©c t·∫°p (10%)
```json
{
  "question": "√îng n·ªôi c·ªßa Nguy·ªÖn VƒÉn A t√™n g√¨?",
  "sql": "SELECT ong.hoTen FROM thanhvien tv JOIN thanhvien cha ON tv.chaId = cha.thanhVienId AND tv.dongHoId = cha.dongHoId JOIN thanhvien ong ON cha.chaId = ong.thanhVienId AND cha.dongHoId = ong.dongHoId WHERE tv.hoTen = 'Nguy·ªÖn VƒÉn A' AND tv.dongHoId = ?"
}
```

### S·ªë l∆∞·ª£ng examples c·∫ßn thi·∫øt:
- **Minimum**: 200 examples (40 m·ªói lo·∫°i)
- **Good**: 500 examples (100 m·ªói lo·∫°i)
- **Best**: 1000+ examples (200+ m·ªói lo·∫°i)

---

## üõ†Ô∏è C√îNG C·ª§ V√Ä SETUP

### Hardware y√™u c·∫ßu:
- **Minimum**: GPU 8GB VRAM (RTX 3060)
- **Recommended**: GPU 16GB+ VRAM (RTX 4090, A100)
- **Alternative**: Google Colab Pro ($10/month)

### Software stack:
```bash
# Python packages
pip install transformers torch peft bitsandbytes accelerate datasets sqlparse

# Ollama (ƒë√£ c√≥)
ollama pull qwen2.5-coder:7b
```

### Training v·ªõi LoRA:
```python
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=16,  # Rank
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)
```

---

## üìã K·∫æ HO·∫†CH TH·ª∞C HI·ªÜN CHI TI·∫æT

### Week 1: Setup & Data Preparation
- [ ] Export database schema ƒë·∫ßy ƒë·ªß
- [ ] T·∫°o 50 c√¢u h·ªèi m·∫´u + SQL
- [ ] Setup Qwen2.5-Coder local
- [ ] Test prompt engineering

### Week 2: Prompt Engineering
- [ ] Thi·∫øt k·∫ø prompt template t·ªët
- [ ] Test v·ªõi 50 examples
- [ ] ƒê√°nh gi√° accuracy
- [ ] Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn fine-tune kh√¥ng

### Week 3-4: Data Generation (n·∫øu c·∫ßn fine-tune)
- [ ] T·∫°o 500-1000 examples
- [ ] Validate data quality
- [ ] Split train/val/test (80/10/10)

### Week 5-6: Fine-tuning (n·∫øu c·∫ßn)
- [ ] Setup training environment
- [ ] Fine-tune v·ªõi LoRA
- [ ] Evaluate v√† optimize
- [ ] Save best model

### Week 7: Integration
- [ ] T√≠ch h·ª£p v√†o backend
- [ ] T·∫°o API endpoint
- [ ] Testing end-to-end
- [ ] Deploy

---

## üéØ B∆Ø·ªöC TI·∫æP THEO

B·∫°n c·∫ßn tr·∫£ l·ªùi:

1. **GPU**: B·∫°n c√≥ GPU kh√¥ng? Lo·∫°i g√¨? VRAM bao nhi√™u?
2. **Budget**: C√≥ th·ªÉ d√πng Colab Pro kh√¥ng?
3. **Timeline**: C·∫ßn ho√†n th√†nh trong bao l√¢u?
4. **Accuracy target**: C·∫ßn ƒë·ªô ch√≠nh x√°c bao nhi√™u % ƒë·ªÉ ch·∫•p nh·∫≠n?
5. **Data**: B·∫°n c√≥ th·ªÉ t·∫°o ƒë∆∞·ª£c bao nhi√™u c√¢u h·ªèi m·∫´u?

Sau khi c√≥ c√¢u tr·∫£ l·ªùi, t√¥i s·∫Ω:
1. ‚úÖ Vi·∫øt script export database schema
2. ‚úÖ T·∫°o template generate training data
3. ‚úÖ Vi·∫øt code test v·ªõi Qwen2.5-Coder
4. ‚úÖ Thi·∫øt k·∫ø prompt template t·ªëi ∆∞u
5. ‚úÖ H∆∞·ªõng d·∫´n fine-tuning n·∫øu c·∫ßn

**B·∫°n mu·ªën b·∫Øt ƒë·∫ßu t·ª´ ƒë√¢u?**
