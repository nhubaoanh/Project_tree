# âš¡ Tá»I Æ¯U Tá»C Äá»˜ - AI SERVICE

## ğŸ“Š HIá»†N TRáº NG

**Há»‡ thá»‘ng cá»§a báº¡n:**
- CPU: AMD Ryzen (8 cores)
- RAM: 7.36GB (84.9% used)
- GPU: KhÃ´ng cÃ³
- Model: 1.5B parameters

**Tá»‘c Ä‘á»™ hiá»‡n táº¡i:**
- Láº§n Ä‘áº§u: ~60-90 giÃ¢y
- CÃ¡c láº§n sau: ~30-60 giÃ¢y

---

## âœ… ÄÃƒ Tá»I Æ¯U (Tá»± Ä‘á»™ng)

### 1. Giáº£m `max_new_tokens`: 512 â†’ 256
- **Cáº£i thiá»‡n**: Nhanh hÆ¡n ~2x
- **Tá»‘c Ä‘á»™ má»›i**: ~30-45 giÃ¢y
- **Trade-off**: Váº«n Ä‘á»§ cho SQL queries (SQL ngáº¯n)

---

## ğŸš€ Tá»I Æ¯U THÃŠM

### Option 1: Táº¯t `do_sample` (Deterministic)

**File:** `ai-service/sql_generator.py`

```python
outputs = self.model.generate(
    **inputs,
    max_new_tokens=256,
    temperature=0.0,      # Thay vÃ¬ 0.1
    do_sample=False,      # Thay vÃ¬ True
    pad_token_id=self.tokenizer.eos_token_id
)
```

**Cáº£i thiá»‡n**: Nhanh hÆ¡n ~20-30%  
**Trade-off**: Káº¿t quáº£ Ã­t Ä‘a dáº¡ng hÆ¡n (OK cho SQL)

---

### Option 2: Giáº£m `max_new_tokens` xuá»‘ng 128

**File:** `ai-service/sql_generator.py`

```python
outputs = self.model.generate(
    **inputs,
    max_new_tokens=128,   # Thay vÃ¬ 256
    ...
)
```

**Cáº£i thiá»‡n**: Nhanh hÆ¡n ~2x  
**Trade-off**: CÃ³ thá»ƒ bá»‹ cáº¯t vá»›i SQL phá»©c táº¡p

---

### Option 3: DÃ¹ng Caching

**File:** `ai-service/sql_generator.py`

```python
from functools import lru_cache
import hashlib

class SQLGenerator:
    def __init__(self):
        self.model = model_loader.get_model()
        self.tokenizer = model_loader.get_tokenizer()
        self.prompt_builder = PromptBuilder()
        self.cache = {}  # Simple cache
    
    def generate_sql(self, question):
        # Check cache
        cache_key = hashlib.md5(question.encode()).hexdigest()
        if cache_key in self.cache:
            logger.info("Cache hit!")
            return self.cache[cache_key]
        
        # Generate
        result = self._generate_sql_internal(question)
        
        # Save to cache
        self.cache[cache_key] = result
        return result
```

**Cáº£i thiá»‡n**: Instant cho cÃ¢u há»i Ä‘Ã£ há»i  
**Trade-off**: Tá»‘n memory (nhÆ°ng Ã­t)

---

### Option 4: Batch Processing (Náº¿u nhiá»u queries)

```python
def generate_sql_batch(self, questions):
    # Process multiple questions at once
    prompts = [self.prompt_builder.build_prompt(q) for q in questions]
    inputs = self.tokenizer(prompts, return_tensors="pt", padding=True)
    
    with torch.no_grad():
        outputs = self.model.generate(**inputs, max_new_tokens=256)
    
    return [self._extract_sql(out) for out in outputs]
```

**Cáº£i thiá»‡n**: Nhanh hÆ¡n khi xá»­ lÃ½ nhiá»u queries  
**Trade-off**: Phá»©c táº¡p hÆ¡n

---

## ğŸ’¡ KHUYáº¾N NGHá»Š DÃ€I Háº N

### 1. UPGRADE RAM (Tá»‘t nháº¥t!)
```
Current: 7.36GB
Upgrade: +8GB â†’ 16GB total
Cost: ~500k-1tr VNÄ
Benefit:
  - DÃ¹ng Ä‘Æ°á»£c model 3B (chÃ­nh xÃ¡c hÆ¡n)
  - Nhanh hÆ¡n (Ã­t swap)
  - á»”n Ä‘á»‹nh hÆ¡n
```

### 2. MUA GPU (Náº¿u cÃ³ budget)
```
Option A: GTX 1660 Super (~3-4tr)
  - CUDA cores: 1408
  - VRAM: 6GB
  - Speed: 10-20x faster

Option B: RTX 3060 (~7-8tr)
  - CUDA cores: 3584
  - VRAM: 12GB
  - Speed: 30-50x faster
  - CÃ³ thá»ƒ cháº¡y model 7B
```

### 3. DÃ™NG CLOUD GPU (Náº¿u khÃ´ng muá»‘n mua)
```
Google Colab:
  - Free GPU (T4)
  - 15GB VRAM
  - Giá»›i háº¡n: 12h/session
  - Cost: Free hoáº·c $10/month (Pro)

Kaggle Notebooks:
  - Free GPU (P100)
  - 16GB VRAM
  - Giá»›i háº¡n: 30h/week
  - Cost: Free
```

---

## ğŸ“Š SO SÃNH Tá»C Äá»˜

| Setup | Model | Speed | Cost |
|-------|-------|-------|------|
| **Current** (CPU) | 1.5B | 30-60s | Free |
| CPU + Optimized | 1.5B | 15-30s | Free |
| CPU + 16GB RAM | 3B | 40-80s | ~1tr |
| GPU (GTX 1660) | 3B | 3-5s | ~4tr |
| GPU (RTX 3060) | 7B | 5-10s | ~8tr |
| Cloud GPU | 7B | 3-5s | $10/month |

---

## âš™ï¸ APPLY Tá»I Æ¯U NGAY

### BÆ°á»›c 1: Restart service
```bash
# Ctrl+C Ä‘á»ƒ stop
# Cháº¡y láº¡i
python main.py
```

### BÆ°á»›c 2: Test láº¡i
```bash
curl -X POST http://localhost:7000/test ^
  -H "Content-Type: application/json" ^
  -d "{\"question\":\"CÃ³ bao nhiÃªu ngÆ°á»i?\",\"dongHoId\":\"DH001\"}"
```

### BÆ°á»›c 3: So sÃ¡nh tá»‘c Ä‘á»™
- Láº§n Ä‘áº§u: ~30-45s (thay vÃ¬ 60-90s)
- Láº§n sau: ~15-30s (thay vÃ¬ 30-60s)

---

## ğŸ¯ Káº¾T LUáº¬N

**Vá»›i setup hiá»‡n táº¡i (CPU, 7.36GB RAM):**
- âœ… Model 1.5B lÃ  lá»±a chá»n duy nháº¥t
- âœ… Tá»‘c Ä‘á»™ 30-60s lÃ  **BÃŒNH THÆ¯á»œNG**
- âœ… ÄÃ£ tá»‘i Æ°u `max_new_tokens` â†’ nhanh hÆ¡n ~2x
- âœ… Accuracy váº«n tá»‘t (70-75%)

**Äá»ƒ nhanh hÆ¡n ná»¯a:**
- ğŸ”§ Apply thÃªm Option 1-4 (náº¿u cáº§n)
- ğŸ’° Upgrade RAM lÃªn 16GB (~1tr)
- ğŸ® Mua GPU (~4-8tr)
- â˜ï¸ DÃ¹ng Cloud GPU ($10/month)

**NhÆ°ng vá»›i má»¥c Ä‘Ã­ch há»c táº­p vÃ  test:**
- âœ… Tá»‘c Ä‘á»™ hiá»‡n táº¡i **Äá»¦ DÃ™NG**
- âœ… KhÃ´ng cáº§n tá»‘i Æ°u thÃªm
- âœ… Focus vÃ o há»c AI vÃ  cáº£i thiá»‡n accuracy

---

**Tá»‘c Ä‘á»™ cháº­m lÃ  trade-off cá»§a viá»‡c cháº¡y AI local trÃªn CPU!** ğŸš€

