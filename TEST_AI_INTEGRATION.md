# ğŸ§ª Test AI Integration

## ğŸ“‹ Checklist

### 1. Start AI Service
```bash
cd ai-service
pip install -r requirements.txt
cp .env.example .env
# Sá»­a .env vá»›i DB credentials
python main.py
```

**Expected output:**
```
INFO:     Starting AI Text-to-SQL Service...
INFO:     Loading model: Qwen/Qwen2.5-Coder-7B-Instruct
INFO:     Device: cuda
INFO:     Loading tokenizer...
INFO:     Loading model on GPU...
INFO:     Model loaded successfully!
INFO:     Started server process
INFO:     Uvicorn running on http://0.0.0.0:7000
```

### 2. Start Backend
```bash
cd myFamilyTree
npm run dev
```

**Expected output:**
```
ğŸ¤– AI Service URL: http://localhost:7000
Server running on port 6001
```

### 3. Start Frontend
```bash
cd FE/tree
npm run dev
```

### 4. Test vá»›i cURL

#### Test 1: Health Check
```bash
curl http://localhost:8080/api-core/ai/health
```

**Expected:**
```json
{
  "success": true,
  "healthy": true,
  "message": "AI Service Ä‘ang hoáº¡t Ä‘á»™ng"
}
```

#### Test 2: Ask Question
```bash
curl -X POST http://localhost:8080/api-core/ai/ask \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "CÃ³ bao nhiÃªu ngÆ°á»i trong gia pháº£?",
    "dongHoId": "e9022e64-cbae-11f0-8020-a8934a9bae74"
  }'
```

**Expected:**
```json
{
  "success": true,
  "message": "Truy váº¥n thÃ nh cÃ´ng",
  "data": {
    "question": "CÃ³ bao nhiÃªu ngÆ°á»i trong gia pháº£?",
    "sql": "SELECT COUNT(*) as tong_so FROM thanhvien WHERE dongHoId = ? AND active_flag = 1",
    "confidence": 0.9,
    "results": [{"tong_so": 50}],
    "columns": ["tong_so"],
    "row_count": 1
  }
}
```

### 5. Test trÃªn Frontend

1. Má»Ÿ browser: `http://localhost:3000/ai-chat`
2. Login náº¿u chÆ°a login
3. Thá»­ cÃ¡c cÃ¢u há»i máº«u:
   - "CÃ³ bao nhiÃªu ngÆ°á»i trong gia pháº£?"
   - "Ai lÃ  ngÆ°á»i lá»›n tuá»•i nháº¥t?"
   - "CÃ³ bao nhiÃªu ngÆ°á»i lÃ m nÃ´ng dÃ¢n?"

### 6. Check Logs

#### Backend logs (Terminal 2):
```
============================================================
ğŸ¤– [AI Query] Question: CÃ³ bao nhiÃªu ngÆ°á»i trong gia pháº£?
ğŸ“ [AI Query] DongHoId: e9022e64-cbae-11f0-8020-a8934a9bae74
============================================================

âœ… [AI Query] Response received in 1234ms
ğŸ“ [AI Query] Generated SQL:
   SELECT COUNT(*) as tong_so FROM thanhvien WHERE dongHoId = ? AND active_flag = 1
ğŸ“Š [AI Query] Confidence: 90.0%
ğŸ“¦ [AI Query] Results: 1 rows
ğŸ“‹ [AI Query] Columns: tong_so
ğŸ’¾ [AI Query] Data:
[
  {
    "tong_so": 50
  }
]
============================================================
```

#### AI Service logs (Terminal 1):
```
INFO:     Generating SQL for: CÃ³ bao nhiÃªu ngÆ°á»i trong gia pháº£?
INFO:     Generated SQL: SELECT COUNT(*) as tong_so FROM thanhvien WHERE dongHoId = ? AND active_flag = 1
INFO:     Executing: SELECT COUNT(*) as tong_so FROM thanhvien WHERE dongHoId = %s AND active_flag = 1
INFO:     Query executed successfully. Rows: 1
INFO:     127.0.0.1:52341 - "POST /query HTTP/1.1" 200 OK
```

#### Frontend logs (Browser Console):
```
============================================================
ğŸ¤– [Frontend] Asking AI: CÃ³ bao nhiÃªu ngÆ°á»i trong gia pháº£?
ğŸ“ [Frontend] DongHoId: e9022e64-cbae-11f0-8020-a8934a9bae74
============================================================

âœ… [Frontend] Response received in 1500ms
ğŸ“ [Frontend] SQL: SELECT COUNT(*) as tong_so FROM thanhvien WHERE dongHoId = ? AND active_flag = 1
ğŸ“Š [Frontend] Confidence: 90.0%
ğŸ“¦ [Frontend] Results: 1 rows
ğŸ’¾ [Frontend] Data: [{tong_so: 50}]
============================================================
```

## ğŸ¯ Test Cases

### Basic Queries
- âœ… "CÃ³ bao nhiÃªu ngÆ°á»i trong gia pháº£?"
- âœ… "Ai lÃ  ngÆ°á»i lá»›n tuá»•i nháº¥t?"
- âœ… "CÃ³ bao nhiÃªu ngÆ°á»i lÃ m nÃ´ng dÃ¢n?"

### Personal Info
- âœ… "Nghá» nghiá»‡p cá»§a Nguyá»…n VÄƒn A lÃ  gÃ¬?"
- âœ… "Nguyá»…n VÄƒn A sinh nÄƒm nÃ o?"
- âœ… "Nguyá»…n VÄƒn A sá»‘ng á»Ÿ Ä‘Ã¢u?"

### Relationships
- âœ… "Nguyá»…n VÄƒn A lÃ  con cá»§a ai?"
- âœ… "Nguyá»…n VÄƒn A cÃ³ máº¥y con?"
- âœ… "Con cá»§a Nguyá»…n VÄƒn A tÃªn gÃ¬?"
- âœ… "Vá»£ cá»§a Nguyá»…n VÄƒn A tÃªn gÃ¬?"

### Filtering
- âœ… "Ai lÃ  con trai cá»§a Nguyá»…n VÄƒn A?"
- âœ… "Ai lÃ  con gÃ¡i cá»§a Nguyá»…n VÄƒn A?"

### Complex
- âœ… "Ã”ng ná»™i cá»§a Nguyá»…n VÄƒn C tÃªn gÃ¬?"

## ğŸ› Troubleshooting

### AI Service khÃ´ng start
```bash
# Check Python version
python --version  # Should be 3.10+

# Check CUDA (if using GPU)
python -c "import torch; print(torch.cuda.is_available())"

# If no GPU, use CPU
# Edit ai-service/.env: DEVICE=cpu
```

### Backend khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c AI Service
```bash
# Check AI Service is running
curl http://localhost:7000/health

# Check .env
cat myFamilyTree/.env | grep AI_SERVICE_URL
# Should be: AI_SERVICE_URL=http://localhost:7000
```

### Frontend khÃ´ng gá»i Ä‘Æ°á»£c API
```bash
# Check backend is running
curl http://localhost:8080/api-core/ai/health

# Check authentication
# Make sure you're logged in and have valid token
```

## âœ… Success Criteria

- [ ] AI Service starts successfully
- [ ] Backend connects to AI Service
- [ ] Frontend can ask questions
- [ ] Logs show full flow (Frontend â†’ Backend â†’ AI Service â†’ Database)
- [ ] Results display correctly in UI
- [ ] Confidence score is reasonable (> 70%)
- [ ] SQL queries are correct

## ğŸ“Š Performance Metrics

- **First query**: ~30-60s (model loading)
- **Subsequent queries**: ~1-3s
- **Confidence**: Should be > 70% for most queries
- **Accuracy**: Should be > 80% for basic queries

---

**Ready to test!** ğŸš€
